\section{TED}
\label{p2:chap_ted}
\textit{In this chapter, we describe TED, our TracE Diagnosis tool (Fig. \ref{fig:c4-approach}), we illustrate its functioning on two use cases and evaluate. }
%\vspace{2ex}\vfill
%\minitoc
%\vspace{5cm}
{\color{blue} XXX: breve introduction sur ce qu'est TED, en lien avec le chapitre precedent }
\subsection{TED Mechanism}\label{sec:c4-tedmec}

\subsubsection{Architecture}

\begin{figure}[htb]
 %\begin{center}
  \includegraphics[scale=0.6]{chap4/images/archi-eps-converted-to.pdf}
 %\end{center}
\caption{TED Architecture}
\label{fig:c4-approach}
\end{figure}

TED handles two main phases. The {\em Preprocessing and trace generation} phase takes as input - a reference trace and a source file to generate an execution trace $T$ via the \textit{multimedia Toolkit}. The traces are preprocessed. This step is very important for a successful outcome of the analysis as a non cleansed and non normalized data can lead to
spurious and meaningless results \cite{Morchen06}. A parsed trace (c.f. figure \ref{fig:c4-trace}) $T_p$ (respectively $T_r$) is obtained from $T$ (respectively reference trace), by removing some redundant informations or by modifying others. If needed, we can abstract traces via the {\em abstractor} tool. We further explain in section \ref{sec-expe} the utility of such abstraction and how our distance-based algorithms can be adapted to such traces.\\

\begin{figure*}[bt]
\begin{center}
  \subfigure[original trace] { \label{fig-trace-a} \includegraphics[scale=0.45]{chap4/images/uc_trace1-eps-converted-to.pdf}}
%\hspace{5mm}
  \subfigure[parsed trace] { \label{fig-trace-b} \includegraphics[scale=0.45]{chap4/images/uc_trace2-eps-converted-to.pdf}}
  %\subfigure[abstracted trace] { \label{fig-trace-c} \includegraphics[scale=0.4]{images/uc_trace3-eps-converted-to.pdf}}
\end{center}
\caption{Example of data preparation}
\label{fig:c4-trace}
\end{figure*}

The {\em Diagnosis process}, is the second and core phase of TED. The {\em distance selector engine} chooses an appropriate distance from the  {\em Distances} database and applies it to the anomaly it needs to detect. For instance, if we want to detect a desynchronization anomaly, the {\em distance selector engine}  applies the occurrence distance on  $T^p$  and the reference trace  $T^r$.



%  Note that, given two traces $T_1$ and $T_2$, produced with a pipeline described in 
% section \ref{sec-trace}, the temporal distance is computed between sequence events of a plugin $p$ in $T_1$, and sequence events of the same plugin in $T_2$.
%
 {\color{blue}{ (XXX Detail the fact that the temporal distance is done by comparing plugins each other and give explanations??)}.}


\subsubsection{Use cases}
%#####################################Use Case#################################################

% {\color{blue} Explain here Data preparation before "engine selection": pruning, why, when, command gstreamer to disturb initial execution trace, 
% with figures.} 
% We show the main steps of TED trough an use case and synthetic data.\\
We consider the following scenario. A user is watching a video and (a) the video streaming becomes very slow or, (b) the sound is desynchronized with images.\\


In the \textit{Preprocessing and Trace Generation} phase, we decode the movie with {\em gstreamer} to obtain the reference trace $T_r$. We use a gstreamer element {\em identity} \cite{gstreamer}, %with property {\em error-after} 
with property {\em sleep-time}, to obtain a A/V/S desync. anomaly (scenario b). %an error after a given number $N$ of buffers. 
The abnormal trace obtained is $T$. We generate another abnormal trace, with a slow streaming anomaly (scenario a)
by a stress of CPU and memory in the system.
 $T_r$ and $T$ have the format of Fig. \ref{fig-trace-a}. In order to reduce the size of the dataset for easier processing by temporal distance, we keep only four events columns,
 which correspond to {\em timestamps, Debug level, function } and the first argument of the {\em message}. As a result, the dataset was 
reduced to $26,5\%$ of its original size (Fig. \ref{fig-trace-b}).\\%  Fig. \ref{fig-trace-c} shows the corresponding abstracted trace.\\

 In the \textit{Diagnosis process} phase, the developer uses TED as follow:
\begin{figure*}[hbt]
\begin{center}
  \subfigure[execution trace with a {\em slow streaming anomaly}. The developer selects the distance to apply (scenario a)] {\label{fig-ted-a} \includegraphics[scale=0.8]{chap4/images/uc_diag1_new-eps-converted-to.pdf}}
\hspace{15mm}
 \subfigure[TED finds and detects one anomaly:  A/V/S desync. anomaly (scenario b)] { \label{fig-ted-b} \includegraphics[scale=0.8]{chap4/images/uc_diag2_new-eps-converted-to.pdf}}
\vspace{4mm}
\end{center}
\caption{TED's help}
\label{fig:c4-ted}
\end{figure*}

%Talk about TED, show a figure of it performances
%Expliquer que le developpeur a le choix: il peut avoir une idée d'un pb de sa trace et vouloir confirmation; il peut ne rien savoir 
%et essayer de chercher s'il y'a un problem (find pb) ou chercher tous les potentiels pbs (All pbs)

%\begin{enumerate}
% \item Select two files: they should have the same format, parsed or abstracted.
%\item Select a diagnosis type; TED offers many choices:
\begin{itemize}
\item The developer has an idea of the anomaly and just want to verify if his hypothesis is true or not. He selects the distance to apply 
and TED gives the diagnosis. In Fig. \ref{fig-ted-a}, {\em temporal distance} is used (scenario a). The developer suspects a slow streaming anomaly (P3). TED detects the anomaly and returns the value of temporal distances between the two traces per plugins. %bulles dans la figure pour montrer les fonctions discriminantes obtenues 
TED points out the {\em audioresample} plugin to be the one with the most dissimilar events between the two traces.\\
\item The developer has no idea of what is happening and would like to find if there exists an anomaly in $T$. He selects the choice {\em find anomaly}, and TED applies successively all the distances, and stops when one of them gives a non-zero value (Fig. \ref{fig-ted-b}). In scenario b, dropping and occurrences distances have been tested 
and a A/V/S desync. anomaly was detected.\\
\item The developer wants to find all potential anomalies in $T$ (choice {\em all tests}). Indeed, it is possible to have simultaneously a A/V/S desync. and a player crash anomaly. 
\end{itemize}
%\item {\em check} if there exist a bug. A diagnosis is given concurrently to distance values of distances (Fig. \ref{fig-ted}).
%\end{enumerate}

By using TED, a developer analyzing an execution trace is notified of anomalies, their types and where they appear in the trace (the plugin concerned). TED is a time saver for developers as they can quickly detect anomalies in their execution traces and fix them.

\subsection{TED Evaluation}
We conducted a set of experiments to demonstrate the quality and efficiency of our proposed execution trace diagnosis tool. 
First we use standard distance algorithms to compare traces and show the semantic added-value brought by TED. We also show how helpful this automatic tool can be for 
developers, by an evaluation of TED scalability and precision. Finally, we discuss the importance of trace abstraction and show how to adapt TED to take into account abstract traces.\\
 
%on low-level events as on abstracted events the answer of TED is pertinent and we show that the algorithms are scalable.\\
\textbf{System configuration:} Our prototype system is implemented in Python 3.2. 
%The tool used to abstract is {\em FrameMiner} \cite{ck2012} with parameters fixed to  $k=10$,$\varepsilon=75\%$,$m=2$ and $l=300$. 
The experiments were run on an Intel Xeon E5-2650 at 2.0GHz with 32 Gigabytes of RAM with Linux.\\

\textbf{Data Set:} We use traces from two real applications, described below:

{\em Gstreamer application:} Gstreamer \cite{gstreamer} is a powerful open source multimedia framework for creating streaming applications, used by several corporations 
as Intel, Nokia, STMicroelectronics and many others.
%It is modular, pipeline-based and open source.
For these experiments we decoded several movies using Gstreamer on a Linux platform, 
with the $ffmpeg$ plugin for video decoding.\\
{\em GSTapps application}: It is a test video decoding application for STMicroelectronics development boards. 
This application is widely used by STMicroelectronics developers.
%In our trace, the application is run on a STi7208 SoC, which is used in high definition set-top boxes produced by STMicroelectronics.
The  execution trace contains both application events and system-level events.
It is generated from a $ST40$ core of the SoC, which is dedicated to application execution and device
control.\\
Table \ref{tab-data} gives a description of reference traces. \\%of these data, for the reference trace.\\
\begin{table}[h!tbp]
\caption{Experimental Dataset}
  \begin{center}

\begin{tabular}{|c|c|c|c|}
\hline
%\textbf{Video} & \textbf{\small ET size} & \textbf{\small Events nb} & \textbf{\small AE nb}\\
%valeurs des .dat et fichiers d'origine!(# .parsed) Le préciser dans le texte the values represented are those of traces obtained par toolkit
\textbf{Video} & \textbf{\small Duration} & \textbf{\small Nb. of events} & \textbf{\small Size}\\
\hline
\textit{generic}& $5s$   & $15,110$  & $2.9M_o$ \\
%\textit{pub}&  $40s$  & $90,909$ &  $10.7M_o$\\
\textit{pub}&  $30s$  & $74,510$ &  $14.3M_o$\\
\textit{movie}& $3628s$   &$12,423,095$  &$2457,6M_o$  \\
\hline
SDK2& $335s$   &  $2,382,720$ & $73.2M_o$ \\
\hline
\end{tabular}
\end{center}
\label{tab-data}
\end{table}
% \textbf{Faut-il ajouter une colonne avec les informations des traces abstraites pour chacun des exemples?, mettre également les statistiques en termes de 
% nombre d'events par exemple, pour toutes les traces perturbés que nous avons utilisé?}\\

\subsubsection{Comparison with standards sequence distances}
We used existing implementations of two well known sequence distances {\em DTW} \cite{dtw} and {\em LCS}\cite{lcs00}. These implementations are given by mlpy \cite{mlpy}, a Python module for Machine Learning built. 
For our experimentations, the events of execution traces 
were coded as integers, as required by {\em mlpy}. 
$LCS(x,y)$ returns the length of the longest common sequence of x and y. We then obtain distance between x and y by $d(x,y)=|x|+|y|-2*LCS(x,y)$.
% The non-linear transformation $d'$ described in section \ref{subsec-dist}, is applied to the results of standards {\em LCS} and {\em DTW}.
%We convert the events into numeric values to use the existent implementation
Table \ref{tab-dist-stand} shows the values of distances obtained w.r.t to two execution traces given as input. 
\begin{table}[h!tbp]

  \caption{DTW and LCS distances}
  \begin{center}
    \begin{tabular}{|c|c|c|}
      \hline
      & \textbf{DTW} & \textbf{LCS} \\
      \hline
      $(T_r,T_1)$& $509069$  & $28035$\\
      \hline
      $(T_r,T_2)$&  $504472$   & $28086$ \\
      \hline
      $(T_r,T_3)$& $920600$   &$18377$ \\
      \hline
    \end{tabular}
  \end{center}
  \label{tab-dist-stand}
\end{table}

$T_r$ is the reference trace of {\em generic video}; $T_1$ is obtained by using the gstreamer element {\em identity} before the video decoding plugin,
 with property $sleep-time=30000$. With $sleep-time=5000$, we obtained $T_2$ and a visual degradation slighter than those related to $T_1$, not really perceptible. 
%; it is almost invisible and is obtained by decreasing the value of $sleep-time$ property. 
Naturally, we expect that $d(T_r,T_1)>d(T_r,T_2)$. It is the case with {\em DTW} distance ($509069>504472$), but not with 
{\em LCS} distance. $T_3$ is obtained with property {\em error-after}. An error occurs during the video streaming, after a given number $N$ of buffers.
 $N=500$. We obtained for instance $dtw(T_r,T_3)=920600$.\\
 The observation is that $T_1,T_2$ and $T_3$ are far from $T_r$. With standard distance algorithms, we can only compute distance values but we have no idea which type of anomalies are in the traces.\\
% \begin{table}[h!tbp]
% 
%   \caption{DTW and LCS distances}
%   \begin{center}
%     \begin{tabular}{|c|c|c|}
%       \hline
%       & \textbf{DTW} & \textbf{LCS} \\
%       \hline
%       $(T_r,T_1)$& $509069$  & $28035$\\
%       \hline
%       $(T_r,T_2)$&  $504472$   & $28086$ \\
%       \hline
%       $(T_r,T_3)$& $920600$   &$18377$ \\
%       \hline
%     \end{tabular}
%   \end{center}
%   \label{tab-dist-stand}
% \end{table}

In our proposal, for $T_1$, TED diagnoses a slow streaming problem. He  gives $132090.5$ as $d_3(T_r,T_1)$, and $131525$ as $d_3(T_r,T_2)$ which confirm our expectation of $d(T_r,T_1)>d(T_r,T_2)$, and the fact that the video execution of $T_1$ is slower than the one of $T2$. For $T_3$, TED diagnoses a player crash anomaly in addition to giving a distance value between  $T_3$ and  $T_r$.\\
%EXPLIQUER EN DEUX LIGNES COMMENT NOUS NOUS SOMMES MIEUX
% Show that we couldn't capture anything with theses kind of distance (LCS, DTW). We can't interpret. Now we have a distance ++

% \begin{table}[h!tbp]
% 
%   \caption{DTW and LCS distances}
%   \begin{center}
%     \begin{tabular}{|c|c|c|}
%       \hline
% %\textbf{Video} & \textbf{\small ET size} & \textbf{\small Events nb} & \textbf{\small AE nb}\\
% %valeurs des .dat et fichiers d'origine!(# .parsed) Le préciser dans le texte the values represented are those of traces obtained par toolkit
%       & \textbf{DTW} & \textbf{LCS} \\
%       \hline
%       $(T_r,T_1)$& $0,999998035$  & $0,99996433$\\
%       \hline
%       $(T_r,T_2)$&  $0,999998017$   & $0,99996439$ \\
%       \hline
%       $(T_r,T_3)$& $0,9999989$   &$0,99994558$ \\
%       \hline
%     \end{tabular}
%   \end{center}
%   \label{tab-dist-stand}
% \end{table}
\subsubsection{Running time and Scalability}
Fig. \ref{fig-rt} reports the wall clocks of TED for {\em occurrence} and {\em dropping} distance, when varying 
events number of execution traces. Horizontal axis represent the maximum number of events of the two compared traces.
%Notice that we take the maximum number of events, for two execution traces to compare. 
In practice, we consider 
as $\theta=0.25$, as threshold of $occ\_ratio$. One can notice that, for traces of more than $1G_o$, corresponding to approximatively $4,000,000$ events, 
TED can give a diagnosis in less than $10s$. For the {\em pub} video of table \ref{tab-dist-stand}, an output is obtained in $0.12s$.
% Each point represents the execution of the same distance, in this case, $D_1$
The experiments showed that the proposed methods can scale to real application traces. This makes TED suitable for analysis of real traces.\\

\begin{figure}[h!btp]
 \begin{center}
  \includegraphics[]{chap4/images/tedTime_old-eps-converted-to.pdf}
 \end{center}
\caption{Running time}
\label{fig-rt}
\end{figure}
%\textbf{Dire quelques phrases sur TED applique sur une trace abstraite?}

\subsubsection{Precision}
In order to evaluate the accuracy of the diagnosis done by TED, we run TED on a sample of $300$ execution traces as shown in 
Table \ref{tab-precision}. The first observation is that all execution traces initially considered as normal were diagnosed as such by TED. However, the tool
 gave $14$ {\em false-true} which are execution traces considered by TED as normal but which contain anomalies. Thus, TED has a precision of $95.33\%$. A reason 
of this lack of precision can be the value of threshold 
for {\em occurrence distance}. We fixed it at $\theta=0.25$ but we will surely gain to adapt the threshold value to the length of the video decoded. We are currently testing the correlation between the video length and the threshold value. \\

\begin{table}[h!tbp]
\caption{TED precision}
\begin{center}
 \begin{tabular}{|c|c|c|}
\hline
\textbf{Nb. traces} & \textbf{Initially} & \textbf{With TED} \\
\hline
\multirow{2}{3cm}{Sample of 300 traces}
 & normal: 130   & normal: 144 \\  \cline{2-3}
 & abnormal: 170    & abnormal: 156 \\
\hline
    \end{tabular}
  \end{center}
  \label{tab-precision}
\end{table}


